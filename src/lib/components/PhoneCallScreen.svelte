<script lang="ts">
	import { onMount } from 'svelte';
	import FaVolumeMute from 'svelte-icons/fa/FaVolumeMute.svelte';
	import FaVolumeUp from 'svelte-icons/fa/FaVolumeUp.svelte';
	import FaPhoneSlash from 'svelte-icons/fa/FaPhoneSlash.svelte';
	import FaPhone from 'svelte-icons/fa/FaPhone.svelte';
	import FaCheckCircle from 'svelte-icons/fa/FaCheckCircle.svelte';
	import FaClosedCaptioning from 'svelte-icons/fa/FaClosedCaptioning.svelte';
	import FaMicrophone from 'svelte-icons/fa/FaMicrophone.svelte';
	import FaMicrophoneSlash from 'svelte-icons/fa/FaMicrophoneSlash.svelte';

	import { DEFAULT_UNMUTE_CONFIG, instructionsToPlaceholder, type Instructions, type UnmuteConfig } from '$lib/config';

	import { useMicrophoneAccess } from '$lib/useMicrophoneAccess';
	import { useAudioProcessor, type AudioProcessor } from '$lib/useAudioProcessor';
	import { base64DecodeOpus, base64EncodeOpus } from '$lib/audioUtil';
	import type { ChatMessage } from '$lib/chatHistory';

	import { generateReport, now, userSettingsStore, userStore, type ReportData, userProfileStore, updateUserSettings } from '$lib/stores';
	import { goto } from '$app/navigation';
	import Login from './Login.svelte';
	import { get } from 'svelte/store';
	import { collection, getCountFromServer, getDocs, limit, orderBy, query, Timestamp, where } from 'firebase/firestore';
	import { db, firebaseEnabled } from '$lib/firebase';

	import { format } from 'timeago.js';
	import { PUBLIC_GUEST_DAILY_LIMIT, PUBLIC_SIGNED_USER_DAILY_LIMIT } from '$env/static/public';
    import HistoryButton from './HistoryButton.svelte';
    import QuizButton from './QuizButton.svelte';

	export let name: string = 'Speaking Partner';
	export let description: string = 'Estimate your IELTS speaking score (unofficial) by chatting to AI';
	export let imageUrl: string = '/ielts-examiner.png';

	let reportsToday: number = 0;
    let dailyLimit: number = Infinity; // Default to infinity, will be updated
    let isLoadingUsage: boolean = true; // For potential UI feedback

	let currentSubtitleSentence: string = '';
	let subtitleWords: string[] = [];
	let userSubtitleSentence: string = '';
	let userSubtitleWords: string[] = [];

	let localOnSubtitle: boolean = false;

    const checkUsage = async () => {
        isLoadingUsage = true;
        const currentUser = get(userStore);
        const profile = get(userProfileStore);
        const startOfDay = new Date();
        startOfDay.setHours(0, 0, 0, 0);

        if (currentUser && profile && db) {
            // --- Logic for Signed-in User ---
			dailyLimit = profile.plan === 'plus' ? Infinity : parseInt(PUBLIC_SIGNED_USER_DAILY_LIMIT);

            try {
                const reportsRef = collection(db, 'reports');
                // Query for reports by this user, created on or after the start of today
                const q = query(
                    reportsRef,
                    where('userId', '==', currentUser.uid),
                    where('date', '>=', startOfDay)
                );
                // Use getCountFromServer for efficiency
                const snapshot = await getCountFromServer(q);
                reportsToday = snapshot.data().count;
            } catch (error) {
                console.error('Error fetching report count from Firestore:', error);
                // Fail safe: assume 0 if there's an error
                reportsToday = 0;
            }
        } else {
            // --- Logic for Guest User ---
            dailyLimit = parseInt(PUBLIC_GUEST_DAILY_LIMIT);
            try {
                const localHistory: ReportData[] = JSON.parse(
                    localStorage.getItem('reportHistory') || '[]'
                );
                reportsToday = localHistory.filter(report => new Date(report.date) >= startOfDay).length;
            } catch (error) {
                console.error('Error parsing report history from localStorage:', error);
                reportsToday = 0;
            }
        }
        isLoadingUsage = false;
    };

	$: if ($userStore !== undefined) {
        checkUsage();
    }

	const minVolume = 0;
	const maxVolume = 3.5;
	let volume = maxVolume / 2.0;
	$: progressPercentage = ((volume - minVolume) / (maxVolume - minVolume)) * 100;
	$: isMuted = volume === 0;

	let isOngoing: boolean = false;
	let callDuration: number = 0;

	let unmuteConfig: UnmuteConfig = DEFAULT_UNMUTE_CONFIG;
	let callStartTime: Date | null = null;
	let shouldConnect = false; // This is our main trigger for the connection
	let ws: WebSocket | null = null;
	let readyState: 'CONNECTING' | 'OPEN' | 'CLOSING' | 'CLOSED' | 'FAILED' = 'CLOSED';
	let conversationState: 'bot_speaking' | 'user_speaking' | 'waiting_for_user' = 'waiting_for_user';
	let isReady = false;
	let setupAudio: (mediaStream: MediaStream) => Promise<AudioProcessor | undefined>;
	let shutdownAudio: () => void;
	let processorStore: Writable<AudioProcessor | null>;
	let audioProcessorMain: AudioProcessor | undefined;
	let webSocketUrl: string | null = null;
	let connectingAudio: HTMLAudioElement;
	let callReadyAudio: HTMLAudioElement;
	let podId: string | null = null;
	let chatHistory: ChatMessage[] = [];
	let status: 'online' | 'offline' = 'offline';
	let previousStatus: 'online' | 'offline' = 'offline';
	let isMicMuted = false;
	

	const checkHealth = async () => {
		try {
			const response = await fetch('/api/healthcheck', {
				method: 'POST',
				headers: { 'Content-Type': 'application/json' },
				body: JSON.stringify({ podId: podId })
			});
			const json = await response.json();
			if (response.ok) {
				status = json.status;
			} else {
				status = 'offline';
			}
		} catch (error) {
			console.error('Health check request failed:', error);
			status = 'offline';
		}
	};

	async function notifyBackend(action: 'register' | 'unregister') {
		try {
			// The 'keepalive' flag is CRITICAL for 'unregister'. It ensures the
			// request is sent even if the page is being closed.
			await fetch('/api/pod-session', {
				method: 'POST',
				headers: { 'Content-Type': 'application/json' },
				body: JSON.stringify({ action }),
				keepalive: action === 'unregister'
			}).then(async (res) => {
				const result = await res.json();
				if (result.webSocketUrl) {
					webSocketUrl = result.webSocketUrl;
				}
				if (result.podId) {
					podId = result.podId;
				}
			});
		} catch (e) {
			console.error(`Failed to ${action} connection:`, e);
		}
	}

	onMount(() => {
		const audioProcessor = useAudioProcessor(onOpusRecorded);

		setupAudio = audioProcessor.setupAudio;
		shutdownAudio = audioProcessor.shutdownAudio;
		processorStore = audioProcessor.processorStore;

		isReady = true;

		checkHealth();
		const intervalId = setInterval(checkHealth, 2000);
		
		notifyBackend('register');

		requestWakeLock();

		requestNotificationPermission();

		return () => {
			if (shutdownAudio) shutdownAudio();
			if (intervalId) clearInterval(intervalId);
			notifyBackend('unregister');
		};
	});

	const { askMicrophoneAccess, microphoneAccessStatus } = useMicrophoneAccess();

	const formatTime = (totalSeconds: number) => {
		const minutes = Math.floor(totalSeconds / 60)
			.toString()
			.padStart(2, '0');
		const seconds = (totalSeconds % 60).toString().padStart(2, '0');
		return `${minutes}:${seconds}`;
	};

	function onOpusRecorded(opus: Uint8Array) {
		if (ws && readyState === 'OPEN' && !isMicMuted) {
			ws.send(
				JSON.stringify({
					type: 'input_audio_buffer.append',
					audio: base64EncodeOpus(opus)
				})
			);
		}
	}

	const handleStartCall = async () => {
		if (status !== 'online') {
			alert(
				'Bringing up the server. This could take 3-4 minutes.'
			);
			console.warn('Server is not ready yet.');
			return;
		}
		if (!isReady || !setupAudio) {
			console.warn('Audio processor is not ready yet.');
			return;
		}
		// 1. Ask for microphone permission
		const mediaStream = await askMicrophoneAccess();
		requestWakeLock();
		// 2. If we get permission, set up audio processing
		if (mediaStream) {
			readyState = 'CONNECTING';
			if ((navigator as any).audioSession) {
				(navigator as any).audioSession.type = 'playback';
			}
			audioProcessorMain = await setupAudio(mediaStream);
			if (audioProcessorMain && typeof audioProcessorMain.setVolume === 'function') {
            	audioProcessorMain.setVolume(volume);
        	}
			isOngoing = true;
			callDuration = 0;
			// 3. Set our trigger to true. The reactive block below will handle the connection.
			shouldConnect = true;
			callStartTime = new Date();
		} else {
			// Handle the case where the user denies permission
			console.error('Microphone access was denied.');
			alert('You must allow microphone access to start the call.');
		}
	};

	const handleStopCall = async (shouldGenerateReport: boolean = true) => {
		if (!shouldGenerateReport && isOngoing) {
			if (confirm('Are you sure to end the ongoing call? Report will not be generated.')) {
				goto('/');
			}
			return;
		}
		if (shouldGenerateReport && !isReportReady) {
			if (confirm("The report is not ready yet. Are you sure you want to stop the call?")) {
				goto('/');
			}
			return;
		}
		isOngoing = false;
		shouldConnect = false;
		shutdownAudio();
		callStartTime = null;
		readyState = 'CLOSED';

		if (shouldGenerateReport) {
			// Navigate to the special 'latest' route immediately.
			// The report page will show the 'generating' state from the store.
			goto('/report/latest');

			// Now, start the report generation in the background. The page is already
			// listening for the result via the reportStore.
			await generateReport(chatHistory, isReportReady, callDuration);
		} else {
			goto('/');
		}
	};

	const handleMicBtnClick = () => {
		isMicMuted = !isMicMuted;
	};

	const handleSubtitleBtnClick = async () => {
		const currentUser = get(userStore);
		if (currentUser) {
			const isOn = $userSettingsStore.showUserSubtitles && $userSettingsStore.showAiSubtitles;
			userSettingsStore.update(currentSettings => {
                return {
                    ...currentSettings,
                    showUserSubtitles: !isOn,
                    showAiSubtitles: !isOn
                };
            });
		} else {
			localOnSubtitle = !localOnSubtitle;
		}
	};

	const requestWakeLock = async () => {
		try {
			const wakeLock = await navigator.wakeLock.request('screen');
		} catch (err: any) {
			// The wake lock request fails - usually system-related, such as low battery.
			console.error(`${err.name}, ${err.message}`);
		}
	};

    const requestNotificationPermission = async () => {
        if (!('Notification' in window)) {
            console.log('This browser does not support desktop notification.');
            return;
        }
        try {
            const permission = await Notification.requestPermission();
            if (permission === 'granted') {
                console.log('Notification permission granted.');
            } else {
                console.log('Notification permission denied.');
            }
        } catch (error) {
            console.error('Error requesting notification permission:', error);
        }
    };

	const sendServerReadyNotification = async () => {
        if (!('Notification' in window)) {
            return;
        }

        if (Notification.permission === 'granted') {
            new Notification('Server is Ready!', {
                body: 'The AI is online. You can start your call now.',
                icon: '/favicon.png'
            });
        }
    };

	$: callDuration = callStartTime
		? Math.round(($now.getTime() - callStartTime.getTime()) / 1000)
		: 0;

	$: isReportReady = callDuration >= 60;

	$: reportTooltip = isReportReady
		? 'Ready to generate a report'
		: 'Report not ready yet. Try to chat a bit more.';

	$: {
        if (status === 'online' && previousStatus !== 'online') {
            if (callReadyAudio) {
                callReadyAudio.play().catch(e => console.error("Call ready audio failed to play:", e));
            }
            sendServerReadyNotification();
        }
        previousStatus = status;
    }

	$: {
		if (connectingAudio) {
			// Wait for the audio element to be bound
			if (readyState === 'CONNECTING') {
				// Play the sound. The .catch is good practice for browser audio policies.
				connectingAudio.play().catch((e) => console.error('Audio play failed', e));
			} else {
				// If the state is anything else, stop the sound and reset it.
				connectingAudio.pause();
				connectingAudio.currentTime = 0;
			}
		}
	}

	$: {
		if (shouldConnect && !ws && webSocketUrl != null) {
			readyState = 'CONNECTING';
			const newWs = new WebSocket(webSocketUrl, ['realtime']);

			newWs.onopen = async () => {
				readyState = 'OPEN';
				let finalInstructions: Instructions = unmuteConfig.instructions;
				const currentUser = get(userStore);
				const settings = get(userSettingsStore);
				let summaries: string[] = [];

				if (currentUser && settings.memory && db) {
					try {
						const reportsRef = collection(db, 'reports');
						const q = query(
							reportsRef,
							where('userId', '==', currentUser.uid),
							orderBy('date', 'desc'),
							limit(5)
						);
						const querySnapshot = await getDocs(q);
						summaries = querySnapshot.docs.map(
							(doc) => {
								const data = doc.data() as ReportData;
								return format((data.date as any).toDate()) + ": " + data.conversationSummary;
							}
						);
					} catch (error) {
						console.error("Failed to fetch conversation history for memory:", error);
						// If fetching fails, we'll just proceed without memory.
					}
				} else if (!currentUser) {
					const reportHistory = JSON.parse(localStorage.getItem('reportHistory') || '[]') as ReportData[];
					summaries = reportHistory.sort((a, b) => new Date(b.date).getTime() - new Date(a.date).getTime()).slice(0, 5).map(
						(data) => {
							return format(data.date) + ": " + data.conversationSummary;
						}
					);
				}
				if (summaries.length > 0) {
					const memoryPrefix = `For context, here are summaries of our last ${summaries.length} conversations:\n\n${summaries.map((s, i) => `${s}`).join('\n')}\n\nPlease keep these in mind for continuity. Now, let's begin today's conversation. If possible mention one of the last conversation when you greet the user initially.`;
					
					const originalInstructionsText = instructionsToPlaceholder(unmuteConfig.instructions);
					
					const fullText = `${memoryPrefix}\n\n${originalInstructionsText}`;

					finalInstructions = { type: 'constant', text: fullText };
				} else {
					// This is a first-time user with no conversation history.
					const welcomePrefix = `This is the user's first conversation. Please provide a warm and encouraging welcome. Let them know you're an AI partner here to help them practice English, and an IELTS score estimation will be generated after the conversation and they can stop whenever they want.`;
					const originalInstructionsText = instructionsToPlaceholder(unmuteConfig.instructions);
					const fullText = `${welcomePrefix}\n\n${originalInstructionsText}`;

					finalInstructions = { type: 'constant', text: fullText };
				}
				const sessionPayload = {
					instructions: finalInstructions,
					// voice: 'unmute-prod-website/ex04_narration_longform_00001.wav', // Female voice
					voice: 'unmute-prod-website/developer-1.mp3', // Male voice
					allow_recording: true
				};
				newWs.send(
					JSON.stringify({
						type: 'session.update',
						session: sessionPayload
					})
				);
			};

			newWs.onmessage = (event) => {
				const message = JSON.parse(event.data);
				if (message.type === 'response.audio.delta') {
					if (message.delta) {
						const opus = base64DecodeOpus(message.delta);
						const ap = audioProcessorMain;
						if (!ap) return;
						ap.decoder.postMessage(
							{
								command: 'decode',
								pages: opus
							},
							[opus.buffer]
						);
					} else {
						console.error('Received response.audio.delta but message.delta is undefined or null');
					}
				} else if (message.type === 'unmute.additional_outputs') {
					chatHistory = message.args.chat_history;
				} else if (message.type === 'unmute.response.text.delta.ready' || message.type === 'input_audio_buffer.speech_stopped') {
					conversationState = 'bot_speaking';
				} else if (message.type === 'response.audio.done') {
					conversationState = 'waiting_for_user';
				} else if (message.type === 'input_audio_buffer.speech_started') {
					conversationState = 'user_speaking';
					currentSubtitleSentence = '';
					subtitleWords = [];
				} else if (message.type === 'response.text.delta') {
					if (userSubtitleWords.length > 0) {
						userSubtitleSentence = '';
						userSubtitleWords = [];
					}
					currentSubtitleSentence += message.delta + ' ';
					subtitleWords = currentSubtitleSentence.trim().split(/\s+/);
				}  else if (message.type === 'conversation.item.input_audio_transcription.delta') {
					userSubtitleSentence += message.delta + ' ';
					userSubtitleWords = userSubtitleSentence.trim().split(/\s+/);
				} else {
					console.warn('Received unknown message:', message);
				}
			};

			newWs.onclose = () => {
				ws = null;
				// If the connection closes unexpectedly, update the UI state
				if (isOngoing) {
					handleStopCall();
				}
			};

			newWs.onerror = (error) => {
				console.error('WebSocket error:', error);
				readyState = 'FAILED'; // Indicate failure to connect
				ws = null;
				if (isOngoing) {
					handleStopCall();
				}
			};

			ws = newWs;
		} else if (!shouldConnect && ws) {
			ws.close();
			ws = null;
			readyState = 'CLOSED';
		}
	}

	$: {
		if (reportsToday >= dailyLimit) {
            alert(
                `You have reached your daily limit of ${dailyLimit} ${
                    dailyLimit === 1 ? 'report' : 'reports'
                }. Please upgrade your plan or try again tomorrow.`
            );
            goto('/pricing');
        }
	}

	$: {
		if (audioProcessorMain && typeof audioProcessorMain.setVolume === 'function') {
			audioProcessorMain.setVolume(volume);
		}
	}
</script>

<div class="callContainer">
	{#if isMicMuted}
		<div class="announcement">Mic Off</div>
	{/if}
	{#if isReportReady}
		<div class="announcement show-5s">Your IELTS report is ready</div>
	{/if}
	<header class="header">
		<button class="backButton" on:click={() => handleStopCall(false)} aria-label="Back">
			<svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
				<path d="M15.41 7.41L14 6L8 12L14 18L15.41 16.59L10.83 12L15.41 7.41Z" fill="white" />
			</svg>
		</button>
		<div class="callerInfo">
			<h1 class="name-container"><span class={`server-indicator ${status}`}></span> {name}</h1>
			<h5 class="description-container">{description}</h5>
			<p
				style:opacity={readyState === 'CONNECTING' ||
				readyState === 'OPEN' ||
				readyState === 'FAILED'
					? '1'
					: '0'}
			>
				{readyState === 'CONNECTING'
					? 'Connecting...'
					: readyState === 'OPEN'
						? `${formatTime(callDuration)}`
						: readyState === 'FAILED'
							? 'Connection failed. Please try again.'
							: 'PLACEHOLDER'}
			</p>
		</div>
		<div>
			{#if !isOngoing}
				<QuizButton />
				<HistoryButton />
			{/if}
			{#if firebaseEnabled}
				<Login />
			{/if}
		</div>
	</header>

	<main class="mainContent">
		<div class="profileImageContainer">
			<img src={imageUrl} alt={name} class="profileImage" />
		</div>
		<div
			class="profileImageContainerSpinner"
			class:shouldShow={conversationState === 'user_speaking'}
		></div>
		<div
			class="profileImageContainerSpeakingBorder"
			class:shouldShow={conversationState === 'bot_speaking'}
		></div>

		{#if userSubtitleWords.length > 0 && (!get(userStore) ? localOnSubtitle : $userSettingsStore.showUserSubtitles)}
			<div class="subtitle-container user-subtitle-container">
				<p class="subtitle-text-block">
					{userSubtitleWords.join(" ")}
				</p>
			</div>
		{/if}

		{#if subtitleWords.length > 0 && (!get(userStore) ? localOnSubtitle : $userSettingsStore.showAiSubtitles)}
			<div class="subtitle-container">
				<p class="subtitle-text-block">
					{subtitleWords.join(" ")}
				</p>
			</div>
		{/if}
	</main>

	<footer class="footerControls">
		{#if !isOngoing && readyState !== 'CONNECTING'}
			<button class={`controlButton startCallButton ${status}`} on:click={handleStartCall}>
				{#if status === 'online'}
					<FaPhone />
				{:else}
					<div class="spinner"></div>
				{/if}
			</button>
			{#if status !== 'online'}
				<h5>
					Bringing up the server (This could take 3-4 mins)
				</h5>
			{/if}
			<div class="loadingBarContainer" class:finished={status === 'online'}>
				<div class="loadingBar"></div>
			</div>
		{:else}
			<div class="volume-slider-container">
				<button on:click={() => volume = isMuted ? 1.0 : 0} class="volume-icon" aria-label={isMuted ? 'Unmute' : 'Mute'}>
					{#if isMuted}
						<FaVolumeMute />
					{:else}
						<FaVolumeUp />
					{/if}
				</button>
				<input
					type="range"
					min={minVolume}
					max={maxVolume}
					step="0.01"
					bind:value={volume}
					class="volume-slider"
					aria-label="Adjust AI volume"
					style="--progress-percentage: {progressPercentage}%;"
				/>
			</div>
			<button
				class="controlButton subtitleButton"
				class:subtitleButtonOn={!get(userStore) ? localOnSubtitle : ($userSettingsStore.showUserSubtitles && $userSettingsStore.showAiSubtitles)}
				on:click={handleSubtitleBtnClick}
			>
				<FaClosedCaptioning />
			</button>
			<button class="controlButton endCallButton" on:click={(e) => handleStopCall()}>
				<FaPhoneSlash />
			</button>
			<button
				class="controlButton micButton"
				class:mute={!isMicMuted}
				on:click={handleMicBtnClick}
			>
				{#if isMicMuted}
					<FaMicrophoneSlash />
				{:else}
					<FaMicrophone />
				{/if}
			</button>
			<div
				class="reportIndicator"
				class:ready={isReportReady}
				class:not-ready={!isReportReady}
				title={reportTooltip}
				aria-label={reportTooltip}
				role="img"
				style="display: none"
			>
				<FaCheckCircle />
				<div class="reportTooltip">{reportTooltip}</div>
			</div>
		{/if}

		{#if $microphoneAccessStatus === 'denied'}
			<p class="error-text">Microphone access denied. Please enable it in your browser settings.</p>
		{/if}
	</footer>
	<audio src="/connecting.wav" bind:this={connectingAudio} loop></audio>
	<audio src="/call-ready.wav" bind:this={callReadyAudio}></audio>
</div>

<style>
	.error-text {
		color: red;
		position: absolute;
		bottom: 20px;
		width: 100%;
		text-align: center;
	}

	.callContainer {
		position: fixed;
		width: 100%;
		height: 100%;
		overflow: hidden;
		display: flex;
		flex-direction: column;
		color: white;
		overflow: hidden; /* Ensure no scrollbars appear */
		font-family:
			-apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
		background: radial-gradient(circle at 50% 50%, #5a4743, #3a2723);
	}

	.header {
		padding: 50px 20px 20px;
		text-align: center;
		position: relative;
	}

	.backButton {
		position: absolute;
		left: 15px;
		top: 15px;
		background: none;
		border: none;
		color: white;
		cursor: pointer;
		padding: 5px;
	}

	.callerInfo h1 {
		margin: 0;
		font-size: 2.2rem;
		font-weight: 600;
	}

	.callerInfo p {
		margin: 5px 0 0;
		font-size: 1rem;
		color: #d1d1d6;
		font-weight: 500;
	}

	.mainContent {
		flex-grow: 1;
		display: flex;
		justify-content: center;
		align-items: center;
	}

	.profileImageContainer {
		width: 150px;
		height: 150px;
		border-radius: 50%;
		overflow: hidden;
		box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
	}

	.profileImage {
		width: 100%;
		height: 100%;
		object-fit: cover;
	}

	.footerControls {
		display: flex;
		justify-content: center;
		align-items: center;
		padding: 0 20px 50px 20px;
    	gap: 12px;
	}

	.controlButton {
		width: 40px;
		height: 40px;
		border-radius: 50%;
		background-color: rgba(255, 255, 255, 0.2);
		border: none;
		color: white;
		display: flex;
		justify-content: center;
		align-items: center;
		cursor: pointer;
		transition: background-color 0.2s ease;
	}
	:global(.micButton.mute svg) {
		transform: scale(0.8);
	}
	.subtitleButton, .micButton {
		width: 25px;
		height: 25px;	
	}

	.subtitleButtonOn, .micButton.mute {
		background-color: rgba(0, 0, 0, .8);
	}

	.controlButton.subtitleButtonOn:active, .micButton.mute:active {
		background-color: rgba(0, 0, 0, 0.7);
	}

	.controlButton.subtitleButtonOn:hover, .micButton.mute:hover {
		background-color: rgba(0, 0, 0, 0.6);
	}

	.controlButton.controlButton:active, .controlButton.micButton:active {
		background-color: rgba(255, 255, 255, 0.4);
	}

	.controlButton:hover {
		background-color: rgba(255, 255, 255, 0.3);
	}

	.endCallButton {
		background-color: #ff3b30;
	}

	.endCallButton:active {
		background-color: #d93229;
	}

	.endCallButton:hover {
		background-color: #ff5c5c;
	}

	.startCallButton {
		background-color: #34c759;
	}

	.startCallButton.offline {
		background-color: #5a4743;
	}

	.startCallButton:active {
		background-color: #28a745;
	}

	.startCallButton:hover {
		background-color: #45d160;
	}

	.server-indicator.online {
		background-color: #4caf50;
	}

	.server-indicator {
		width: 12px;
		height: 12px;
		border-radius: 50%;
		border: 1px solid white;
		margin-top: 15px;
		margin-right: 12px;
	}

	.name-container {
		display: flex;
		padding-left: calc(50% - 145px);
	}

	.description-container {
		font-style: italic;
	}

	.spinner {
		width: 24px;
		height: 24px;
		border: 3px solid rgba(255, 255, 255, 0.3);
		border-top-color: #fff; /* This creates the "pac-man" effect */
		border-radius: 50%;
		animation: spin 1s linear infinite;
	}

	.break {
		flex-basis: 100%;
		width: 0;
	}

	.profileImageContainerSpinner.shouldShow {
		display: block;
	}
	.profileImageContainerSpinner {
		display: none;
		position: fixed;
		width: 170px;
		height: 170px;
		border-radius: 50%;
		border-radius: 50%;
		border: 3px dashed #34c759;
		animation: spin 5s linear infinite;
	}

	.profileImageContainerSpeakingBorder.shouldShow {
		display: block;
	}
	.profileImageContainerSpeakingBorder {
		display: none;
		position: fixed;
		width: 170px;
		height: 170px;
		border-radius: 50%;
		border-radius: 50%;
		border: 1px solid lightgrey;
		animation: pulse 1s infinite;
	}

	.reportIndicator {
		height: 20px;
   		width: 20px;
	}

	.reportIndicator .reportTooltip {
		position: absolute;
		bottom: 140%;
		left: 50%;
		transform: translateX(-50%);
		background: rgba(0, 0, 0, 0.85);
		color: #fff;
		padding: 6px 8px;
		border-radius: 6px;
		font-size: 12px;
		white-space: nowrap;
		opacity: 0;
		pointer-events: none;
		transition:
			opacity 0.15s ease,
			transform 0.15s ease;
	}

	.reportIndicator .reportTooltip::after {
		content: '';
		position: absolute;
		top: 100%;
		left: 50%;
		transform: translateX(-50%);
		border-width: 6px;
		border-style: solid;
		border-color: rgba(0, 0, 0, 0.85) transparent transparent transparent;
	}

	.reportIndicator.ready {
		color: #34c759;
	}

	.reportIndicator.not-ready {
		opacity: 0.5;
	}

	.reportIndicator:hover .reportTooltip {
		opacity: 1;
		transform: translateX(-50%) translateY(-2px);
	}

	.loadingBarContainer {
        width: 250px;
        height: 6px;
        background-color: rgba(255, 255, 255, 0.2);
        border-radius: 3px;
        overflow: hidden;
        position: absolute;
		bottom: 30px;
    }

	.loadingBar {
        width: 0%; /* Start at 0 width */
        height: 100%;
        background-color: #34c759; /* Green color to match the 'ready' button */
        border-radius: 3px;
        animation: fill-progress 50s linear forwards;
    }

	.loadingBarContainer.finished .loadingBar {
        width: 100%;
		animation: none;
    }

	.loadingBarContainer.finished {
        animation: fade-out 1s ease-out forwards;
	}

	.subtitle-container {
		position: absolute;
		bottom: 25%; /* Position it above the footer controls */
		left: 10%;
		right: 10%;
		display: flex;
		flex-wrap: wrap; /* Allow words to wrap to the next line */
		justify-content: center;
		align-items: center;
		gap: 0.2em; /* Small space between words */
		pointer-events: none; /* Prevent subtitles from blocking clicks */
	}

	.subtitle-text-block {
		background-color: rgba(0, 0, 0, 0.75);
		color: #fff;
		padding: 0.5em 0.5em;
		border-radius: 4px;
		font-weight: 500;
		box-decoration-break: clone;
		-webkit-box-decoration-break: clone;
	}

	.user-subtitle-container .subtitle-text-block {
		background-color: #fff;
		color: rgba(0, 0, 0, 0.75);
	}

    .volume-slider-container {
		position: absolute;
		bottom: 120px;
        display: flex;
        align-items: center;
        gap: 0.75rem;
        width: 100%;
        max-width: 300px;
        margin: 1rem auto;
    }

    .volume-icon {
        color: white;
        background: none;
        border: none;
        padding: 0;
        cursor: pointer;
        width: 1.5rem;
        height: 1.5rem;
    }
    
    .volume-slider {
        -webkit-appearance: none;
        appearance: none;
        width: 100%;
        cursor: pointer;
        outline: none;
        background: transparent;
    }

    .volume-slider::-webkit-slider-thumb {
        -webkit-appearance: none;
        appearance: none;
        height: 20px;
        width: 20px;
        background-color: #fff;
        border-radius: 50%;
        border: none;
        margin-top: -6px; 
    }

    .volume-slider::-moz-range-thumb {
        height: 20px;
        width: 20px;
        background-color: #fff;
        border-radius: 50%;
        border: none;
    }

    .volume-slider::-webkit-slider-runnable-track {
        height: 4px;
        background: linear-gradient(to right, 
            #ffffff var(--progress-percentage), 
            rgba(255, 255, 255, 0.3) var(--progress-percentage)
        );
        border-radius: 2px;
    }

    .volume-slider::-moz-range-track {
        height: 4px;
        background: linear-gradient(to right, 
            #ffffff var(--progress-percentage), 
            rgba(255, 255, 255, 0.3) var(--progress-percentage)
        );
        border-radius: 2px;
    }

	.announcement {
		position: fixed;
		top: 20px;
		left: 50%;
		transform: translateX(-50%);
		z-index: 9999;

		padding: 12px 20px;
		background-color: #2c3e50;
		color: #ecf0f1;
		border-radius: 8px;
		box-shadow: 0 4px 12px rgba(0, 0, 0, 0.25);
		
		font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
		font-size: 0.95rem;
		font-weight: 500;
		text-align: center;
	}

	.announcement.show-5s {
		animation: slideInAndOut 5s ease-in-out forwards;
	}

	@keyframes slideInAndOut {
		0% {
			opacity: 0;
			transform: translate(-50%, -50px);
		}
		10% {
			opacity: 1;
			transform: translate(-50%, 0);
		}
		90% {
			opacity: 1;
			transform: translate(-50%, 0);
		}
		100% {
			opacity: 0;
			transform: translate(-50%, -50px);
		}
	}

	@keyframes fade-out {
		0% {
			opacity: 1;
		}
		80% {
			opacity: 1;
		}
		100% {
			opacity: 0;
		}
	}

    @keyframes fill-progress {
        from {
            width: 0%;
        }
        to {
            width: 90%;
        }
    }

	@keyframes spin {
		to {
			transform: rotate(360deg);
		}
	}

	@keyframes pulse {
		0% {
			transform: scale(1);
			opacity: 1;
		}
		50% {
			transform: scale(1.1);
			opacity: 0;
		}
		100% {
			transform: scale(1);
			opacity: 1;
		}
	}
</style>
